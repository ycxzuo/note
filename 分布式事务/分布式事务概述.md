# 分布式事务概述

## 事务

### 概念

是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行

### 特性

事务拥有4个特性，也就是所谓的ACID特性

* 原子性（Atomicity）
  * 事务作为一个整体执行，包含在其中的操作要么被执行，要么都不被执行
* 一致性（Consistency）
  * 事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态，中间状态不能被察觉
* 隔离性（Isolation）
  * 一个事务所做的修改在最终提交以前，对其他事务是不可见的
* 持久性（Durability）
  * 一个事务一旦提交，它对数据库中数据的改变就应该是永久性的

### 隔离级别

事务拥有4个隔离级别

* Read uncommitted
  * 概念
    * 读未提交，也就是一个事务可以读取另一个未提交事务的数据
  * 造成问题
    * 脏读
* Read committed（Oracle、Sql Server等默认隔离级别）
  * 概念
    * 读提交，也就是一个事务要等另一个事务提交后才能读取
  * 造成问题
    * 不可重复读（Update操作）
* Repeatable read（Mysql默认隔离级别）
  * 概念
    * 重复读，也就是开始事务时，不再允许修改操作
  * 造成问题
    * 幻读（Insert操作）
* Serializable
  * 概念
    * 串行化，事务串行化执行
  * 造成问题
    * 效率低，耗性能

## 分布式事务

### 概念

事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点上，通常一个分布式事务中会涉及对多个数据源或业务系统的操作。

### CAP定理

#### 概念

WEB服务无法同时满足以下三个条件

* 一致性（Consistency）
  * 数据在多个副本之间能否保持一致的特性
* 可用性（Availability）
  * 系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果
* 分区容错性（Partition tolerance）
  * 分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障，是基本要求

在一个WEB服务之多只能同时满足以上两个属性，显然，任何横向扩展策略都要依赖于数据分区，因此，设计人员必须在一致性和可用性之间做出选择

### BASE理论

#### 概念

在分布式系统中，我们往往追求可用性，BASE理论的提出，是对CAP定理的一个扩充，它是指

* Basically Available（基本可用）
  * 分布式系统在出现不可预知故障的时候，允许损失部分可用性
    * 响应时间上的损失：例如查询时间由1s在出现故障后变成了5s
    * 系统功能上的损失：例如在双十一的情景下，给用户引导到一个降级页面
* Soft state（软状态）
  * 允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时
* Eventually consistent（最终一致性）
  * 最终一致性强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态

### 分布式一致性

#### 一致性问题

在分布式系统中要解决的一个重要问题就是数据的复制，因为数据复制需要时间。数据的复制只要是为了满足以下两个需求

* 增加系统的可用性，避免单点故障
* 让每个系统能在不同的地方都能拿到数据副本

#### 数据一致性

就是指在一个数据副本进行更新时能确保所有的数据副本也会更新。

* 解决方案
  * 很容易想到的方案就是在写入的时候使用同步阻塞的方式，完成写入并使数据副本全部同步时再取消阻塞
* 问题诞生
  * 当某个场景有很多写的操作时，会造成整体性能急剧下降

#### 一致性级别

在数据一致性的问题上，看出保证数据的一致性和系统运行的性能是需要考虑和权衡的地方，一致性级别诞生

* 强一致性
  * 如同数据一致性的最初解决方案一样，系统写入的是什么，读出来的就是什么，但是实现起来对系统性能影响极大
* 弱一致性
  * 不承诺多久之后可以读到写入的值，但是数据最终会达到一致的状态
* 最终一致性
  * 弱一致性的一个特例，系统会在一定时间内达到数据一致性，是比较推崇的一种模型

### 分布式环境问题

#### 通信异常

由于网络本身的不可靠性，导致各个服务之间的通信可能出现故障，网络光纤、硬件设备或是系统不可用都会造成网络通信问题，并且单机访问比网络通信要快很多，也会影响到收发过程，导致消息丢失或者延迟

#### 网络分区

* 概念
  * 当网络发生异常情况，导致分布式系统中部分节点之间的网络延迟不断增大，最终导致所有节点中只有部分节点直接可以正常通行

在极端条件下，这些局部小集群需要完成原本整个分布式系统才能完成的功能，包括对数据的事务处理，会对数据一致性产生巨大的挑战

#### 三态

分布式系统的每一次请求与响应，存在特有的三态概念

* 成功
* 失败
* 超时（与单机模式的区别点）
  * 此时发送方无法确定请求是否处理成功
  * 产生超时的情况
    * 该请求并没有被成功地发送到接收方，而是在发送过程中就发生了消息丢失现象
    * 请求成功地被接收方接收后，将响应反馈给发送方的过程中，发生了消息丢失现象

#### 节点故障

指某台服务器节点出现宕机或“僵死”现象

### 常见分布式事务模型

#### X/Open XA协议（XA协议）

##### 模型

```mermaid
graph LR
A[AP应用程序] -->|本地| B[RM资源管理器集群]
A[AP应用程序] -->|TX| C[TM事务管理器]
B[RM资源管理器集群] -->|XA| C[TM事务管理器]
C[TM事务管理器] -->|XA| B[RM资源管理器集群]
```

最早的分布式事务模型是`X/Open`国际联盟提出的`X/Open Distributed Transaction Processing`（`DTP`）模型，`DTP`模型如上图

* 全局事务管理器（TM，`Transaction Manager`）
  * 负责管理全局事务状态与参与的资源，协同资源一起提交或者回滚
* 多个资源管理器（RM，`Reource Manager`）
  * 负责具体资源的操作

##### 流程

* 应用程序（AP，Application）向TM申请开始一个全局事务
* 针对要操作的RM，AP先向TM注册（记录AP操作过哪些RM，及分支事务），TM通过XA接口函数通知相应的RM开启分布式事务的子事务，接着AP就可以对该RM进行操作
* 当AP对所有RM操作完毕后，AP会根据执行情况通知TM提交或回滚该全局事务，TM通过XA接口函数通知各RM完成操作。TM会先要求各个RM做预提交，所有RM返回成功后，再要求RM做正式提交。

##### 原子性

XA协议使用2PC（Two Phase Commit，两阶段提交）原子提交协议来保证分布式事务原子性

* 准备阶段
  * TM向RM发送准备消息，如果RM的本地事务操作执行成功，则返回成功，否则返回失败
* 提交阶段
  * 如果TM收到所有RM回复消息为成功，则向每个RM发送提交消息，否则发送回滚消息；RM根据TM指令执行提交或回滚的本地事务操作，释放事务处理过程中使用的锁资源

##### 隔离性

基于XA协议实现的分布式事务的隔离性是由每个 RM 本地事务的隔离性来保证的，当一个分布式事务的所有子事务都是隔离的，那么这个分布式事务天然的就实现了隔离性。

例如Mysql使用的2PL（Two-Phase Locking，两阶段锁）机制来控制本地事务的并发，保证隔离性。将锁操作分为加锁和解锁两个阶段，并保证两个阶段完全不相交。加锁阶段，只加锁，不放锁。解锁阶段，只放锁，不加锁

##### 一致性

Mysql通过MVCC（Multi Version Concurrency Control，多版本并发控制）机制，为每个一致性状态生成快照（Snapshot），每个事务看到的都是各Snapshot对应的一致性状态，从而也就保证了本地事务的中间状态不会被观察到。

但是在分布式事务中，如果当资源一已提交而资源二还未提交，只能读到资源一上子事务执行的内容，读不到 资源二上的子事务执行的内容，违反了事务一致性的要求。

XA协议没有定义全局Snapshot，官方建议使用串行化的隔离级别来保证分布式事务，但是性能很差，很多分布式数据库都实现了**分布式MVCC机制**来提供全局的一致性读，用一个集中式或者逻辑上单调递增的东西来控制生成全局Snapshot，每个事务或者每条 SQL 执行时都去获取一次，从而实现不同隔离级别下的一致性。比如Google的Spanner就是用TrueTime来控制访问全局Snapshot。

##### 小结

* 优势
  * 一旦商业数据库实现了XA协议，使用分布式事务的成本也比较低，对业务几乎都没有侵入
  * 尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。
* 缺陷
  * XA无法满足高并发场景，mysql的XA实现，没有记录prepare阶段日志，主备切换回导致主库与备库数据不一致。许多nosql也没有支持XA，这让XA的应用场景变得非常狭隘。
  * 实现复杂，牺牲了可用性，对性能影响较大，不适合高并发高性能场景



#### TCC模型（Try-Confirm-Cancel）

通过对业务逻辑的分解来实现分布式事务

##### 三段业务逻辑

* 初步操作 try
  * 完成所有业务检查，预留必须的业务资源
* 确认操作 Confirm
  * 真正执行的业务逻辑，不作任何业务检查，只使用 Try 阶段预留的业务资源。因此，只要 Try 操作成功，Confirm 必须能成功。另外，Confirm 操作需满足幂等性，保证一笔分布式事务有且只能成功一次
* 取消操作 Cancel
  * 释放 Try 阶段预留的业务资源。同样的，Cancel 操作也需要满足幂等性

##### 分布式事务模型分为三部分

* 主业务服务
  * 整个业务活动的发起方，负责发起并完成整个业务活动
* 从业务服务
  * 整个业务活动的参与方，负责提供TCC业务操作，实现`try-confirm-cancel`三个接口，供主服务使用
* 业务活动管理器
  * 整个业务活动的管理者，负责管理控制整个业务活动，例如记录、维护整个TCC活动的事务状态和每个从业务的子事务状态，并在业务活动提交时调用所有从业务的Confirm操作，在业务取消时调用所有的从业务服务的Cancel操作

##### 一个完整的 TCC 分布式事务流程如下

1. 主业务服务首先开启本地事务
2. 主业务服务向业务活动管理器申请启动分布式事务主业务活动
3. 针对要调用的从业务服务，主业务活动先向业务活动管理器注册从业务活动，然后调用从业务服务的Try接口
4. 当所有从业务服务的Try接口调用成功，主业务服务提交本地事务；若调用失败，主业务服务回滚本地事务
5. 若主业务服务提交本地事务，则TCC模型分别调用所有从业务服务的Confirm接口；若主业务服务回滚本地事务，则分别调用Cancel接口
6. 所有从业务服务的Confirm或Cancel操作完成后，全局事务结束

##### 原子性

TCC模型也使用2PC原子提交协议来保证事务原子性。Try操作对应2PC的一阶段准备（Prepare）；Commit操作对应二阶段提交（Commit）；Cancel操作对应二阶段回滚（Rollback），所以TCC就是应用层的2PC

##### 隔离性

TCC的隔离性思想就是通过业务的改造，在第一阶段结束之后，从底层数据库源层面加锁过渡到上层业务层加锁，从而释放底层资源锁，放宽分布式事务锁协议，提高业务并发性能。

以银行资金交易举例，用户发起交易时

* 第一阶段：检查用户资金是否充足，，如果资金充足，冻结用户本次交易资金，这笔资金被业务隔离，不允许除本事务之外的其他事务动用
* 第二阶段：扣除第一阶段预冻结的资金，增加卖家资金，完成交易。

采用业务加锁的方式，隔离用户冻结资金，在第一阶段结束后直接释放底层资源锁，该用户和卖家的其他交易都可以立刻并发执行，而不用等到整个分布式事务结束，可以获得更高的并发交易能力。

##### 一致性

以在线下单为例

* 第一阶段：Try阶段会去扣库存
* 第二阶段：Confirm阶段则是去更新订单状态，如果更新订单失败，则进入Cancel阶段，会去恢复库存。

总之，TCC就是通过代码人为实现了两阶段提交，不同的业务场景所写的代码都不一样，复杂度也不一样，因此，这种模式并不能很好地被复用。

从系统的角度来看，确实有问题与不确定性。在第一阶段执行结束到第二阶段执行结束之间，有一段时间的延时，在这段时间内，看似任何用户都不享有这笔资产。

但是，从用户的角度来考虑这个问题的话，这个时间间隔可能就无所谓或者根本就不存在。特别是当这个时间间隔仅仅是几秒钟，对于具体沟通资产转移的用户来讲，这个过程是隐蔽的或确实可以接受的，且保证了结果的最终一致性。

当然，对于这样的系统，如果确实需要查看系统的某个一致性状态，可以采用额外的方法实现。

一般来讲，服务之间的一致性比服务内部的一致性要更加容易弱化，这也是为什么 XA 等直接在资源层面上实现通用分布式事务的模型会注重一致性的保证，而当上升到服务层面，服务与服务之间已经实现了功能的划分，逻辑的解耦，也就更容易弱化一致性，这就是 SOA 架构下 BASE 理论的最终一致性思想。

BASE 理论是指 BA（Basic Availability，基本业务可用性）；S（Soft state，柔性状态）；E（Eventual consistency，最终一致性）。该理论认为为了可用性、性能与降级服务的需要，可以适当降低一点一致性的要求，即“基本可用，最终一致”。

业内通常把严格遵循 ACID 的事务称为刚性事务；而基于 BASE 思想实现的事务称为柔性事务。柔性事务并不是完全放弃了 ACID，仅仅是放宽了一致性要求：事务完成后的一致性严格遵循，事务中的一致性可适当放宽。

##### 小结

* 优势
  * 跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些
* 缺陷
  * TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理



#### 本地消息表

##### 核心思想

是将分布式事务拆分成本地事务进行处理。这种方案遵循BASE理论，采用的是最终一致性

##### 步骤

1. 消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ（如Kafka）发送到消息的消费方。如果消息发送失败，会进行重试发送
2. 消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作
3. 生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。如果有靠谱的自动对账补账逻辑，这种方案还是非常实用的

##### 小结

* 优势
  * 一种非常经典的实现，避免了分布式事务，实现了最终一致性
* 缺陷
  * 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理



#### 消息事务+最终一致性

实际上是基于消息中间件的两阶段提交，本质上是对消息中间件的一种特殊利用，它是将本地事务和发消息放在了一个分布式事务里，保证要么本地操作成功成功并且对外发消息成功，要么两者都失败，开源的RocketMQ就支持这一特性。

将一个分布式事务拆成一个消息事务（A系统的本地操作+发消息）+B系统的本地操作，其中B系统的操作由消息驱动，只要消息事务成功，那么A操作一定成功，消息也一定发出来了，这时候B会收到消息去执行本地操作，如果本地操作失败，消息会重投，直到B操作成功，这样就变相地实现了A与B的分布式事务。

上面的方案能够完成A和B的操作，但是A和B并不是严格一致的，而是最终一致的，我们在这里牺牲了一致性，换来了性能的大幅度提升。当然，这种玩法也是有风险的，如果B一直执行不成功，那么一致性会被破坏。

##### 小结

* 优势
  * 实现了最终一致性，不需要依赖本地数据库事务
* 缺陷
  * 有风险，主流MQ不支持



#### Sagas 事务模型



