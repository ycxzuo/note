# 集群管理

## 概述

分布式系统集群管理方式大致分为两种

* 主从模式
  * ES、HDFS、HBase
  * Master 作为权威节点，部分操作仅由 Master 执行，并负责维护集群元信息，但是会存在 Master 节点的单点故障，
* 无主模式
  * Cassandra



## 集群角色

### 主节点（Master Node）

主节点负责集群层面的相关操作，管理集群变更

通过配置 `node.master: true` (默认) 使节点具有被选举为 Master 的资格。主节点是全局唯一的，将从有资格成为 Master 的节点中进行选举

主节点也可以作为数据节点，但尽可能做少量工作，因此生成环境应尽量分离主节点和数据节点，创建独立主节点的配置

```properties
node.master: true
node.data: false
```

为了防止数据丢失，每个主节点应该知道有资格称为主节点的数量，默认为 1，每个主节点应该知道形成一个集群的最小数量的主资格节点的数量

假设我们有一个集群，有 3 个主资格节点，当网络发生故障的时候，有可能其中一个节点不能和其他节点进行通信了。这个时候

* 当 `discovery.zen.minimum_master_nodes` 设置为 1 的时候，就会分成两个小的独立集群，当网络好的时候，就会出现数据错误或者丢失数据的情况
* 当 `discovery.zen.minimum_master_nodes` 设置为 2 的时候，一个网络中有两个主资格节点，可以继续工作，另一部分，由于只有一个主资格节点，则不会形成一个独立的集群，这个时候当网络回复的时候，节点又会从新加入集群。

为避免网络分区时出现多主的情况，配置 `discovery.zen.minnimum_master_nodes` 原则上最小值应该是 `(master_eligible_nodes/2) + 1`

这个参数也可以动态设置：

```properties
PUT localhost:9200/_cluster/settings
{
	“transient”: {
		“discovery.zen.minimum_master_nodes”: 2
	}
}
```



### 数据节点（Data Node）

负责保存数据、执行数据相关操作：CRUD、搜索、聚合等。数据节点对CPU、内存、I/O 要求较高。一般情况下，数据读写流程只和数据节点交互，不会和主节点打交道

通过配置 `node.data: true` (默认)来使一个节点成为数据节点，也可以通过下面的配置创建一个数据节点：

```properties
node.master: false
node.date: true
node.ingest: false
```



### 预处理节点（Ingest Node）

从 5.0 版本引入。预处理操作允许在索引文档之前，即写入数据之前，通过事先定义好的一系列的 processors（处理器）和 pipeline （管理），对数据进行某种转化、富化。processors 和 pipeline 拦截 bulk 和 index 请求，在应用相关操作后将文档传回给 index 或 bulk API

默认情况下，在所有的节点上启用 ingest，如果想在某个节点上禁用 ingest，则可以添加配置 `node.ingest: false`，也可以通过下面的配置创建一个仅用于预处理的节点：

```properties
node.master: false
node.data: false
node.ingest: true
```



### 协调节点（Coordinating Node）

之前的 Client Node，客户端请求可以发送到集群的任何节点，每个节点都知道任意文档所处的位置，然后转发这些请求，收集数据并返回给客户端，处理客户端请求的节点称为协调节点

协调节点将请求转发给保存数据的数据节点，每个数据节点在本地执行请求，并将结果返回协调节点。协调节点收集完数据后，将每个数据节点的结果合并为单个全局结果。对结果收集和排序的过程可能需要很多 CPU 和内存资源，也可以通过下面的配置创建一个仅用于协调的节点：

```properties
node.master: false
node.data: false
noed.ingest: false
```



### 部落节点（Tribe Node）

tribes（部落）功能允许部落节点在多个集群之间充当联合客户端，如果两个集群的名称相同，部落节点只会连接其中一个



## 集群健康状态

从数据完整性的角度划分，集群健康状态分为三种

* Green，所有的主分片和副分片都正常运行
* Yellow，所有的主分片都正常运行，但不是所有的副分片都正常运行。这意味着存在单点故障风险
* Red，有主分片没有能正常运行

每个索引也有上述三种状态，假设丢失一个副分片，该分片所属的索引和整个集群变为 Yellow 状态，其他索引仍为 Green



## 集群状态

集群状态元数据是全局信息，元数据包括内容路由信息、配置信息等，其中最重要的是内容路由信息，他描述了“哪个分片位于哪个节点”这种信息

集群状态由主节点负责维护，如果主节点从数据节点接收更新，则将这些更新广播到集群其它节点，从 ES 2.0 版本之后，更新的集群状态信息只发增量内容，并且是被压缩的

集群状态有三种

* Green
  * 主分片与副本都分配正常
* Yellow
  * 主分片全部正常分配，有副本分片未能正常分配
* Red
  * 有主分片未能正常分配，例如在服务器磁盘运用到 85% 以上了，重新建立一个索引时



## 集群扩容

当扩容集群、添加节点时，分片会均衡分配到集群的各个节点，从而对索引和搜索过程进行负载均衡

分片副本实现了数据冗余，从而防止硬件故障导致的数据丢失

![ES 扩容](http://tva1.sinaimg.cn/large/0060lm7Tly1g5ucalton7j30p00l6weu.jpg)

分片分配过程中除了让节点均匀存储，还要保证不把主分片和副分片分配到同一节点，避免单个节点故障引起数据丢失

分布式系统如出现单点故障，当节点异常时，ES 会自动处理节点异常，当主节点异常时，集群会重新选举主节点。当某个主分片异常时，会将副分片提升为主分片